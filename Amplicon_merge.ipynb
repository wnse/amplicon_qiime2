{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3314f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554e2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2df(data):\n",
    "    from qiime2 import Metadata\n",
    "    return data.view(Metadata).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a218adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qza_list(json_list, qza_name='asv_rep_seqs_qza'):\n",
    "    from qiime2 import Artifact\n",
    "    qza_list = []\n",
    "    for j in json_list:\n",
    "        with open(j,'rt') as h:\n",
    "            fq2asv = json.load(h)\n",
    "            if qza_name  in fq2asv.keys():\n",
    "                file = fq2asv[qza_name]\n",
    "                if os.path.isfile(file):\n",
    "                    try:\n",
    "                        qza_list.append(Artifact.load(file))\n",
    "                    except Exceptions as e:\n",
    "                        logging.error(e)\n",
    "                else:\n",
    "                    logging.info(f'{file} not exists')\n",
    "            else:\n",
    "                logging.info(f'{qza_name} not in {j}')\n",
    "    return qza_list\n",
    "\n",
    "def merge_qza(qza_list, outfile, para='seq'):\n",
    "    from qiime2.plugins.feature_table.methods import merge\n",
    "    from qiime2.plugins.feature_table.methods import merge_seqs\n",
    "    from qiime2.plugins.feature_table.methods import merge_taxa\n",
    "    from qiime2 import Metadata\n",
    "    \n",
    "    merge_para = None\n",
    "    if para == 'tab':\n",
    "        merge_para = merge\n",
    "        merged = merge_para(qza_list)\n",
    "        merged.merged_table.save(outfile)\n",
    "        return merged.merged_table.view(Metadata).to_dataframe().T\n",
    "    elif para == 'seq':\n",
    "        merge_para = merge_seqs\n",
    "    elif para == 'taxa':\n",
    "        merge_para = merge_taxa\n",
    "    else:\n",
    "        raise(f'{para} not exists in [tab, seq, taxa]')\n",
    "    if merge_para:\n",
    "        merged = merge_para(qza_list)\n",
    "        merged.merged_data.save(outfile)\n",
    "        return merged.merged_data.view(Metadata).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "458711cf-328c-4344-9eeb-fcf0ca7fcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_qza(jsons, outdir):\n",
    "    outdict = {}\n",
    "    seq_qza_list = get_qza_list(jsons, qza_name='asv_rep_seqs_qza')\n",
    "    outfile = os.path.join(outdir, 'merged_seq.qza')\n",
    "    merged_seq = merge_qza(seq_qza_list, outfile=outfile, para='seq')\n",
    "    outdict.update({'merged_seq_qza':outfile})\n",
    "\n",
    "    seq_qza_list = get_qza_list(jsons, qza_name='asv_tax_qza')\n",
    "    outfile = os.path.join(outdir, 'merged_tax.qza')\n",
    "    merged_tax = merge_qza(seq_qza_list, outfile=outfile, para='taxa')\n",
    "    outdict.update({'merged_tax_qza':outfile})\n",
    "\n",
    "    seq_qza_list = get_qza_list(jsons, qza_name='asv_table_qza')\n",
    "    outfile = os.path.join(outdir, 'merged_tab.qza')\n",
    "    merged_tab = merge_qza(seq_qza_list, outfile=outfile, para='tab')\n",
    "    outdict.update({'merged_tab_qza':outfile})\n",
    "    \n",
    "    df_table = pd.concat([merged_seq, merged_tax, merged_tab], axis=1)\n",
    "    outfile = os.path.join(outdir, 'merged_tab.csv')\n",
    "    df_table.to_csv(outfile)\n",
    "    outdict.update({'merged_tab_csv':outfile})\n",
    "    return outdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fbba48a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_seq_tree(seq_qza, outdir):\n",
    "    from qiime2 import Artifact\n",
    "    import qiime2.plugins.phylogeny.actions as phylogeny_actions\n",
    "    from skbio import TreeNode\n",
    "    \n",
    "    rep_seqs = Artifact.load(seq_qza)\n",
    "    outdict = {}\n",
    "    action_results = phylogeny_actions.align_to_tree_mafft_fasttree(\n",
    "        sequences=rep_seqs,\n",
    "    )\n",
    "    aligned_rep_seqs = action_results.alignment\n",
    "    masked_aligned_rep_seqs = action_results.masked_alignment\n",
    "\n",
    "    unrooted_tree = action_results.tree\n",
    "    outfile = os.path.join(outdir, 'merged_unrooted_tree.qza')\n",
    "    unrooted_tree.save(outfile)\n",
    "    outdict.update({'unrooted_tree_qza':outfile})\n",
    "    outfile = os.path.join(outdir, 'merged_unrooted.tree')\n",
    "    unrooted_tree.view(TreeNode).write(outfile)\n",
    "    outdict.update({'unrooted_tree':outfile})\n",
    "    \n",
    "    rooted_tree = action_results.rooted_tree\n",
    "    outfile = os.path.join(outdir, 'merged_rooted_tree.qza')\n",
    "    rooted_tree.save(outfile)\n",
    "    outdict.update({'rooted_tree_qza':outfile})\n",
    "    outfile = os.path.join(outdir, 'merged_rooted.tree')\n",
    "    rooted_tree.view(TreeNode).write(outfile)\n",
    "    outdict.update({'rooted_tree':outfile})\n",
    "    return outdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "daf573e6-68d7-4ce1-899c-9c69e5b8a16e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     bin_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(\u001b[38;5;18;43m__file__\u001b[39;49m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m     pub_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(bin_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../pub/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(pub_path):\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    bin_dir = os.path.split(os.path.realpath(__file__))[0]\n",
    "    pub_path = os.path.join(bin_dir, '../pub/')\n",
    "    if os.path.isdir(pub_path):\n",
    "        sys.path.append(pub_path)\n",
    "    else:\n",
    "        raise(f'{pub_path} not exists')\n",
    "    \n",
    "    from write_json import write_json\n",
    "    from mkdir import mkdir\n",
    "    \n",
    "    parse = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parse.add_argument('-i', '--input', required=True, nargs='+', help='asv dir for analysis (absolute path)')\n",
    "    parse.add_argument('-o', '--outdir', required=True, help='out dir for output files')\n",
    "    args = parse.parse_args()\n",
    "    \n",
    "    indir = args.input\n",
    "    jsons = [os.path.join(i, 'Amplicon_fq2asv.json') for i in indir]\n",
    "    outdir = args.outdir\n",
    "    mkdir(outdir)\n",
    "    logfile = os.path.join(outdir, 'log')\n",
    "    logging.basicConfig(level=logging.INFO, filename=logfile, format='%(asctime)s %(levelname)s %(message)s',datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    try:\n",
    "        info_dict = merge_all_qza(jsons, outdir)\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "    try:\n",
    "        info_dict.update(generate_seq_tree(info_dict['merged_seq_qza'], outdir))\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        \n",
    "    json_out = write_json(info_dict, outdir=outdir)\n",
    "    if not json_out:\n",
    "        logging.info(f'write json failed')\n",
    "        logging.info(f'{info_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae5af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outdirs = ['/mnt/d/Yangk/work/git/amplicon_qiime2/test_out/SRR18505774/',\n",
    "#            '/mnt/d/Yangk/work/git/amplicon_qiime2/test_out/SRR18505775/',\n",
    "#            '/mnt/d/Yangk/work/git/amplicon_qiime2/test_out/SRR18505770/',\n",
    "#            '/mnt/d/Yangk/work/git/amplicon_qiime2/test_out/SRR18505774_silva/'\n",
    "#           ]\n",
    "# names = [i.split('/')[-2]  for i in outdirs]\n",
    "# jsons = [os.path.join(i, 'Amplicon_fq2asv.json') for i in outdirs]\n",
    "\n",
    "# outdir = '/mnt/d/Yangk/work/git/amplicon_qiime2/test_out/merged_out/'\n",
    "# infodict = merge_all_qza(jsons, outdir)\n",
    "# infodict.update(generate_seq_tree(infodict['merged_seq_qza'], outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85cfebc-f9c8-4c7d-a571-2fe02b985d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123a0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6d975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
